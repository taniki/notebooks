{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rasa_nlu.model import Interpreter\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nlu_config = \"\"\"\n",
    "# language: fr\n",
    "# pipeline: tensorflow_embedding\n",
    "# \"\"\"\n",
    "\n",
    "nlu_config = \"\"\"\n",
    "language: fr\n",
    "pipeline:\n",
    "- name: \"nlp_spacy\"\n",
    "- name: \"tokenizer_spacy\"\n",
    "- name: \"intent_featurizer_spacy\"\n",
    "- name: \"intent_entity_featurizer_regex\"\n",
    "- name: \"ner_crf\"\n",
    "- name: \"ner_synonyms\"\n",
    "- name: \"intent_classifier_sklearn\"\n",
    "\"\"\"\n",
    "\n",
    "# nlu_config = \"\"\"\n",
    "# language: fr\n",
    "# pipeline: \"spacy_sklearn\"\n",
    "# \"\"\"\n",
    "\n",
    "%store nlu_config > nlu_config.yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlu_md = \"\"\"\n",
    "## intent:hello\n",
    "- salut\n",
    "- bonjour\n",
    "- hey\n",
    "- hello\n",
    "- coucou\n",
    "- yo\n",
    "\n",
    "## intent:search_dataset\n",
    "- statistiques de [la ville de paris](organization)\n",
    "- je cherche [les données](object) du [ministère de l'intérieur](organization)\n",
    "- j'aimerai connaitre la [qualité de l'air](topic) à Paris\n",
    "- Je voudrai avoir [les chiffres](object) de la [population française](topic)\n",
    "- quel est [mon numéro](object) [RNA](topic) ?\n",
    "- poule 2010\n",
    "- je veux des données\n",
    "- [vigicrue](topic) 2018\n",
    "- base [SIRENE](topic)\n",
    "\n",
    "## intent:confirm\n",
    "- oui\n",
    "- ouais\n",
    "- ouaip\n",
    "- ui\n",
    "- hum oui\n",
    "- hmm ui\n",
    "- ok\n",
    "- c'est ça\n",
    "- yes\n",
    "\n",
    "## intent:deny\n",
    "- non\n",
    "- pas du tout\n",
    "- nope\n",
    "- oui mais non\n",
    "- hm non\n",
    "- hum non\n",
    "- no\n",
    "\n",
    "## intent:thankyou\n",
    "- merci\n",
    "- c'est chouette\n",
    "- cool !\n",
    "- super !\n",
    "\n",
    "## intent:bye\n",
    "- au revoir\n",
    "- à plus\n",
    "- bye\n",
    "- ciao\n",
    "- bonne nuit\n",
    "\n",
    "## lookup:organization\n",
    "organisations.txt\n",
    "\n",
    "## lookup:topic\n",
    "datasets.txt\n",
    "\n",
    "## regex:year\n",
    "- [0-9]{4}\n",
    "\"\"\"\n",
    "%store nlu_md > nlu.md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## importation des noms d'organisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('../pilotage/data/organizations.csv', sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [ x for x in list(df1['name'].astype(str).values) if x != 'nan' ]\n",
    "accronyms = [ x for x in list(df1['acronym'].astype(str).values) if x != 'nan' ]\n",
    "\n",
    "txt = \"\\n\".join(names + accronyms)\n",
    "%store txt > organisations.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('../pilotage/data/datasets.csv', sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head()\n",
    "\n",
    "names = [ x for x in list(df2['title'].astype(str).values) if x != 'nan' ]\n",
    "accronyms = [ x for x in list(df2['acronym'].astype(str).values) if x != 'nan' ]\n",
    "\n",
    "txt = \"\\n\".join(names + accronyms)\n",
    "%store txt > datasets.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrainement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m rasa_nlu.train -c nlu_config.yml --data nlu.md -o models --fixed_model_name nlu --project current --verbose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter = Interpreter.load(\"./models/current/nlu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message = \"Pays de Morlaix 2017\"\n",
    "result = interpreter.parse(message)\n",
    "print(json.dumps(result, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message = \"oui\"\n",
    "result = interpreter.parse(message)\n",
    "print(json.dumps(result, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message = \"non\"\n",
    "result = interpreter.parse(message)\n",
    "print(json.dumps(result, indent=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
